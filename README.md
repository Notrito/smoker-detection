# ğŸš¬ Smoker Detection using LoRA Fine-Tuning

Fine-tuning a pretrained ResNet34 model with LoRA (Low-Rank Adaptation) for binary smoking detection in images.

![Python](https://img.shields.io/badge/Python-3.11-blue)
![PyTorch](https://img.shields.io/badge/PyTorch-2.0-red)
![License](https://img.shields.io/badge/License-MIT-green)

## ğŸ“‹ Project Overview

This project demonstrates **parameter-efficient fine-tuning** using LoRA on a small dataset (1,120 images). By training only 2.14% of the model's parameters, we achieved **89.73% test accuracy** while preserving pretrained ImageNet features.

### Key Features:
- âœ… LoRA implementation from scratch for convolutional layers
- âœ… Only 465K trainable parameters (vs 21.8M full fine-tuning)
- âœ… Balanced performance across both classes (~89% F1-score)
- âœ… Efficient training on free Kaggle GPU

## ğŸ¯ Results

| Metric | Validation | Test |
|--------|------------|------|
| **Accuracy** | 94.44% | 89.73% |
| **Precision (Smoking)** | - | 88.03% |
| **Recall (Smoking)** | - | 91.96% |
| **F1-Score (Smoking)** | - | 89.96% |

**Training Efficiency:**
- Trainable parameters: 465K (2.14%)
- Training time: ~15 minutes (15 epochs)
- GPU: Kaggle T4 (free tier)

## ğŸ—ï¸ Model Architecture

- **Base Model:** ResNet34 (pretrained on ImageNet)
- **LoRA Adaptation:** Applied to layer3 and layer4 (high-level features)
- **LoRA Rank:** 8
- **Classification Head:** Linear(512 â†’ 2)

### Parameter Distribution:
Total: 21.7M parameters
â”œâ”€ Frozen (ImageNet): 21.3M (97.86%)
â””â”€ Trainable: 465K (2.14%)
â”œâ”€ LoRA adapters: 464K
â””â”€ Classification head: 1K

## ğŸ“Š Dataset

**Source:** [Kaggle - Smoking Detection Dataset](https://www.kaggle.com/datasets/sujaykapadnis/smoking)

- **Total Images:** 1,120 (perfectly balanced)
- **Training:** 716 images (64%)
- **Validation:** 180 images (16%)
- **Test:** 224 images (20%)

**Challenges:**
- Low resolution (250Ã—250 pixels)
- Small cigarettes in frame
- High variability in framing and lighting

## ğŸš€ Quick Start

### Installation
git clone https://github.com/YOUR_USERNAME/smoker-detection-lora.git
cd smoker-detection-lora
pip install -r requirements.txt
Training
bash# Run the Jupyter notebook
jupyter notebook notebooks/smoker_detection.ipynb
Or use the training script:
bashpython src/train.py --epochs 15 --lr 1e-4 --rank 8

## ğŸ”§ Technologies Used

PyTorch - Deep learning framework
torchvision - Pretrained models and transforms
scikit-learn - Evaluation metrics
matplotlib/seaborn - Visualization
tqdm - Progress bars

## ğŸ“ˆ Training Details
Hyperparameters:

Learning Rate: 1e-4 (conservative for fine-tuning)
Optimizer: AdamW with weight decay 1e-4
Batch Size: 32
Epochs: 15
LoRA Rank: 8

Data Augmentation:

Random horizontal flip (p=0.5)
Random rotation (Â±10Â°)
Color jitter (brightness, contrast, saturation, hue)

## ğŸ§  What is LoRA?
LoRA (Low-Rank Adaptation) modifies pretrained weights by adding small trainable matrices:
Output = W_frozen Ã— input + (B Ã— A) Ã— input
                             â””â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”˜
                          Low-rank adapter
Where:

W = Original frozen weights (from ImageNet)
A, B = Small trainable matrices (rank << original dimensions)

Benefits:

ğŸ”¹ Massively reduced trainable parameters (~98% reduction)
ğŸ”¹ Prevents overfitting on small datasets
ğŸ”¹ Preserves pretrained knowledge
ğŸ”¹ Faster training and lower memory

## ğŸ“ Project Structure
smoker-detection-lora/
â”œâ”€â”€ notebooks/
â”‚   â””â”€â”€ smoker_detection.ipynb    # Main training notebook
â”œâ”€â”€ src/
â”‚   â”œâ”€â”€ model.py                  # LoRA implementation
â”‚   â”œâ”€â”€ dataset.py                # Custom dataset class
â”‚   â””â”€â”€ train.py                  # Training functions
â”œâ”€â”€ results/
â”‚   â”œâ”€â”€ training_curves.png
â”‚   â””â”€â”€ confusion_matrix.png
â”œâ”€â”€ requirements.txt
â””â”€â”€ README.md

## ğŸ“ Key Learnings

LoRA is highly effective for small dataset fine-tuning
Transfer learning requires careful hyperparameter selection
Data augmentation is crucial with limited data
Parameter efficiency enables training on free/limited resources

## ğŸ”® Future Improvements

 Experiment with different LoRA ranks (4, 12, 16)
 Implement learning rate scheduling
 Try other base models (EfficientNet, Vision Transformer)
 Deploy model with FastAPI/Gradio demo
 Collect more diverse training data


Dataset: Sujay Kapadnis on Kaggle
LoRA Paper: Hu et al., 2021
Pretrained model: torchvision ResNet34

ğŸ“§ Contact
Noel Triguero - noel.triguero@gmail.com
Project Link: https://www.kaggle.com/code/notrito/smoker-detection-with-lora
